# -*- coding: utf-8 -*-
"""Mankei Predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XpsMlIV7scDI5vNndiEWlKNRqyhGm4Pg
"""

# =========================
#  Mankei Umsatz-Prognose (Tmin & Tmax getrennt) + Event + Score
#  - Log-OLS mit: Tmin, Tmax, Niederschlag, Wochentag (+ optional Event)
#  - 90%-Vorhersageintervall, Wahrscheinlichkeiten, 0–100 Score
#  Google Colab kompatibel
# =========================

# Falls nötig:
# !pip -q install statsmodels openpyxl

from pathlib import Path
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

import numpy as np
import pandas as pd
import statsmodels.formula.api as smf
from scipy.stats import t as student_t

# ------------------------------------------------------------
# Datei laden (Colab-Upload oder festen Pfad setzen)
# ------------------------------------------------------------
FILE_PATH = None  # z.B. "/content/Mankei Model.xlsx"

def colab_upload_to_path(default_name="Mankei Model.xlsx") -> Path:
    try:
        from google.colab import files  # type: ignore
    except Exception:
        raise RuntimeError("Colab-Upload nicht verfügbar. Setze FILE_PATH oben auf einen gültigen Pfad.")
    up = files.upload()
    if not up:
        raise RuntimeError("Kein File hochgeladen.")
    name = list(up.keys())[0]
    path = Path(f"/content/{name or default_name}")
    with open(path, "wb") as f:
        f.write(up[name])
    return path

if FILE_PATH is None:
    print("Bitte lade deine Excel-Datei hoch (z. B. 'Mankei Model.xlsx') ...")
    DATA_PATH = colab_upload_to_path()
else:
    DATA_PATH = Path(FILE_PATH)

print(f"Verwende Datei: {DATA_PATH}")

# ------------------------------------------------------------
# Hilfsfunktionen: Parsing & Preprocessing
# ------------------------------------------------------------
def _find_col(cols, keys):
    for kw in keys:
        for c in cols:
            if kw.lower() in str(c).lower():
                return c
    return None

def _to_num(s: pd.Series) -> pd.Series:
    if pd.api.types.is_numeric_dtype(s):
        return pd.to_numeric(s, errors="coerce")
    s2 = (
        s.astype(str)
         .str.replace(r"[€\s]", "", regex=True)
         .str.replace(".", "", regex=False)
         .str.replace(",", ".", regex=False)
    )
    return pd.to_numeric(s2, errors="coerce")

def _normalize_weekday(wd):
    mapping = {
        "montag":0,"dienstag":1,"mittwoch":2,"donnerstag":3,"freitag":4,"samstag":5,"sonntag":6,
        "mo":0,"di":1,"mi":2,"do":3,"fr":4,"sa":5,"so":6,
        "monday":0,"tuesday":1,"wednesday":2,"thursday":3,"friday":4,"saturday":5,"sunday":6
    }
    if isinstance(wd, (int, float)) and int(wd) in range(7):
        return int(wd)
    key = str(wd).strip().lower()
    if key in mapping:
        return mapping[key]
    raise ValueError("Wochentag unbekannt. Erlaubt: 0-6 (Mo=0) oder Namen ('Montag', 'Sa', 'Sunday', ...).")

def _to01_event(s: pd.Series) -> pd.Series:
    if pd.api.types.is_numeric_dtype(s):
        return (pd.to_numeric(s, errors="coerce").fillna(0) > 0).astype(int)
    s = s.astype(str).str.strip().str.lower()
    true_set  = {"1","true","wahr","ja","yes","y","j","x","event"}
    false_set = {"0","false","falsch","nein","no","n",""}
    out = np.where(s.isin(true_set), 1,
          np.where(s.isin(false_set), 0, 0))
    return pd.Series(out, index=s.index, dtype="int64")

def _auto_read_any_sheet_with_header_detection(xlsx_path: Path, max_try_rows=8):
    xls = pd.ExcelFile(xlsx_path)
    for sheet_name in xls.sheet_names:
        for hdr in range(max_try_rows):
            try:
                df = pd.read_excel(xlsx_path, sheet_name=sheet_name, header=hdr)
                df.columns = [str(c).strip() for c in df.columns]
                has_rev = _find_col(df.columns, ["umsatz", "f&b", "revenue", "sales"]) is not None
                has_date_or_wd = (_find_col(df.columns, ["datum", "date"]) is not None) or \
                                 (_find_col(df.columns, ["wochentag","weekday"]) is not None)
                if has_rev and has_date_or_wd:
                    return df, sheet_name, hdr
            except Exception:
                pass
    df = pd.read_excel(xlsx_path, sheet_name=0, header=0)
    df.columns = [str(c).strip() for c in df.columns]
    return df, xls.sheet_names[0], 0

def prepare_data(xlsx_path: Path):
    df, sheet_used, hdr_used = _auto_read_any_sheet_with_header_detection(xlsx_path, max_try_rows=8)

    # Spalten finden
    date_col    = _find_col(df.columns, ["datum", "date"])
    weekday_col = _find_col(df.columns, ["wochentag", "weekday"])
    umsatz_col  = _find_col(df.columns, ["umsatz", "f&b", "revenue", "sales"])
    tmin_col    = _find_col(df.columns, ["tmin", "minimale temperatur", "min temp", "t_min"])
    tmax_col    = _find_col(df.columns, ["tmax", "maximale temperatur", "max temp", "t_max"])
    tavg_col    = _find_col(df.columns, ["tavg", "durchschnitt", "avg temp", "temperatur Ø", "temperatur"])
    precip_col  = _find_col(df.columns, ["niederschlag", "precip", "rain", "regen", "rr"])
    event_col   = _find_col(df.columns, ["event", "eventtag", "is_event", "event day", "event-day", "event_tag"])

    if umsatz_col is None:
        raise RuntimeError(f"Konnte Umsatz-Spalte nicht finden. Spalten entdeckt: {df.columns.tolist()}")

    data = pd.DataFrame()

    # Datum & Wochentag
    data["date"] = pd.to_datetime(df[date_col], errors="coerce") if date_col else pd.NaT
    if weekday_col:
        data["weekday_txt"] = df[weekday_col].astype(str).str.strip()
    else:
        data["weekday_txt"] = ""

    weekday_map_de = {
        "Montag":0,"Dienstag":1,"Mittwoch":2,"Donnerstag":3,"Freitag":4,"Samstag":5,"Sonntag":6,
        "montag":0,"dienstag":1,"mittwoch":2,"donnerstag":3,"freitag":4,"samstag":5,"sonntag":6,
        "Mo":0,"Di":1,"Mi":2,"Do":3,"Fr":4,"Sa":5,"So":6,
        "mo":0,"di":1,"mi":2,"do":3,"fr":4,"sa":5,"so":6,
        "monday":0,"tuesday":1,"wednesday":2,"thursday":3,"friday":4,"saturday":5,"sunday":6
    }
    data["weekday_num"] = data["weekday_txt"].map(weekday_map_de) if weekday_col else np.nan
    data.loc[data["weekday_num"].isna() & data["date"].notna(), "weekday_num"] = data.loc[
        data["weekday_num"].isna() & data["date"].notna(), "date"
    ].dt.weekday

    # Umsatz
    data["umsatz"] = _to_num(df[umsatz_col])

    # Temperaturen getrennt
    tmin = _to_num(df[tmin_col]) if tmin_col else np.nan
    tmax = _to_num(df[tmax_col]) if tmax_col else np.nan
    tavg = _to_num(df[tavg_col]) if tavg_col else np.nan

    if (tmin_col is None) and (tmax_col is None) and (tavg_col is not None):
        print("[Hinweis] Keine Tmin/Tmax-Spalten gefunden – nutze TAVG als Proxy (Tmin=Tmax=Tavg).")
        tmin = tavg
        tmax = tavg

    data["tmin"] = tmin
    data["tmax"] = tmax

    # Niederschlag
    data["precip"] = _to_num(df[precip_col]) if precip_col else np.nan
    data.loc[data["precip"] < 0, "precip"] = 0  # defensiv

    # Event
    if event_col:
        data["event"] = _to01_event(df[event_col])
    else:
        data["event"] = 0

    # Nur gültige Umsätze
    data = data[~data["umsatz"].isna()].copy()

    # Outlier-Trim (Top 1% Umsatz)
    p99 = data["umsatz"].quantile(0.99)
    data_trim = data[data["umsatz"] <= p99].copy()

    # Log-Transform
    data_trim["log_umsatz"] = np.log1p(data_trim["umsatz"])
    for c in ["weekday_num","event"]:
        data_trim[c] = data_trim[c].astype("Int64")

    # Diagnose
    print(f"[Info] Sheet: {sheet_used} | Header-Zeile: {hdr_used}")
    print(f"[Info] Zeitraum: {str(data_trim['date'].min().date()) if data_trim['date'].notna().any() else 'n/a'}"
          f" bis {str(data_trim['date'].max().date()) if data_trim['date'].notna().any() else 'n/a'} |"
          f" N={len(data_trim)} | Eventtage: {int((data_trim['event']==1).sum())}")

    meta = {
        "p99": float(p99),
        "date_min": str(data_trim["date"].min().date()) if data_trim["date"].notna().any() else "n/a",
        "date_max": str(data_trim["date"].max().date()) if data_trim["date"].notna().any() else "n/a",
        "n": int(len(data_trim))
    }
    return data_trim, meta

# ------------------------------------------------------------
# Modell trainieren (Tmin & Tmax) + Score-Kalibrierung
# ------------------------------------------------------------
def load_model(xlsx_path: Path):
    data_trim, meta = prepare_data(xlsx_path)
    need = ["log_umsatz","tmin","tmax","precip","weekday_num"]
    reg = data_trim.dropna(subset=need).copy()
    reg["weekday_num"] = reg["weekday_num"].astype(int)

    use_event = "event" in reg.columns and reg["event"].nunique() > 1
    if use_event:
        reg = reg.dropna(subset=["event"]).copy()
        reg["event"] = reg["event"].astype(int)

    formula = "log_umsatz ~ tmin + tmax + precip + C(weekday_num)" + (" + event" if use_event else "")
    model = smf.ols(formula, data=reg).fit()

    # Score-Kalibrierung (1..99%-Perzentile der log-mean Vorhersagen)
    mu_hist_log = model.fittedvalues
    q1_log  = float(np.percentile(mu_hist_log, 1))
    q99_log = float(np.percentile(mu_hist_log, 99))

    meta.update({
        "formula": formula,
        "r2": float(model.rsquared),
        "n_model": int(model.nobs),
        "score_q1_log": q1_log,
        "score_q99_log": q99_log,
        # Eingabe-Sanity-Ranges
        "tmin_q01": float(reg["tmin"].quantile(0.01)),
        "tmin_q99": float(reg["tmin"].quantile(0.99)),
        "tmax_q01": float(reg["tmax"].quantile(0.01)),
        "tmax_q99": float(reg["tmax"].quantile(0.99)),
        "precip_q99": float(reg["precip"].quantile(0.99)),
        "use_event": bool(use_event)
    })
    return model, meta

# ------------------------------------------------------------
# Vorhersage-API (mit Tmin & Tmax)
# ------------------------------------------------------------
def predict_revenue(model, *, weekday, tmin, tmax, precip, event=False, alpha=0.10):
    """
    90%-Vorhersage-Intervall (alpha=0.10) für Umsatz.
    Inputs: weekday, tmin, tmax, precip, event
    """
    wd = _normalize_weekday(weekday)
    tmin = float(tmin); tmax = float(tmax)
    if tmin > tmax: tmin, tmax = tmax, tmin  # robust gegen vertauschte Eingaben

    # leichte Clamps auf Trainingsbereich
    tmin = float(np.clip(tmin, meta["tmin_q01"], meta["tmin_q99"]))
    tmax = float(np.clip(tmax, meta["tmax_q01"], meta["tmax_q99"]))
    rr = float(max(0.0, precip))
    rr = float(min(rr, meta["precip_q99"]))

    ex = pd.DataFrame({"tmin":[tmin], "tmax":[tmax], "precip":[rr], "weekday_num":[wd], "event":[int(bool(event))]})
    sf = model.get_prediction(ex).summary_frame(alpha=alpha)

    log_point = float(sf["mean"].iloc[0])
    log_lo    = float(sf["obs_ci_lower"].iloc[0])
    log_hi    = float(sf["obs_ci_upper"].iloc[0])

    point = float(np.expm1(log_point))
    lo90  = float(np.expm1(log_lo))
    hi90  = float(np.expm1(log_hi))
    return {
        "inputs": {"weekday_num": wd, "tmin": tmin, "tmax": tmax, "precip": rr, "event": int(bool(event))},
        "point": point, "lo90": lo90, "hi90": hi90, "p90_floor": lo90
    }

# ------------------------------------------------------------
# 0–100 Bedingungs-Score (mit Tmin & Tmax)
# ------------------------------------------------------------
def condition_score(model, meta, *, weekday, tmin, tmax, precip, event=False):
    wd = _normalize_weekday(weekday)
    tmin = float(np.clip(min(tmin, tmax), meta["tmin_q01"], meta["tmin_q99"]))
    tmax = float(np.clip(max(tmin, tmax), meta["tmax_q01"], meta["tmax_q99"]))
    rr = float(max(0.0, precip))
    rr = float(min(rr, meta["precip_q99"]))
    ex = pd.DataFrame({"tmin":[tmin], "tmax":[tmax], "precip":[rr], "weekday_num":[wd], "event":[int(bool(event))]})

    mu_log = float(model.predict(ex)[0])
    lo, hi = meta["score_q1_log"], meta["score_q99_log"]
    raw = 100.0 * (mu_log - lo) / (hi - lo) if hi > lo else 50.0
    return float(np.clip(raw, 0.0, 100.0))

# ------------------------------------------------------------
# Wahrscheinlichkeitsfunktionen (mit Tmin & Tmax)
# ------------------------------------------------------------
def _predictive_params(model, *, weekday, tmin, tmax, precip, event=False, alpha_ci=0.10):
    wd = _normalize_weekday(weekday)
    tmin = float(tmin); tmax = float(tmax)
    if tmin > tmax: tmin, tmax = tmax, tmin
    rr = float(max(0.0, precip))
    X = pd.DataFrame({"tmin":[tmin], "tmax":[tmax], "precip":[rr], "weekday_num":[wd], "event":[int(bool(event))]})
    fr = model.get_prediction(X).summary_frame(alpha=alpha_ci)
    mu = float(fr["mean"].iloc[0])
    df = int(round(model.df_resid))
    tcrit = student_t.ppf(1 - alpha_ci/2.0, df)
    sigma = (float(fr["obs_ci_upper"].iloc[0]) - mu) / tcrit
    return mu, sigma, df

def prob_within_pct_of_point(model, *, weekday, tmin, tmax, precip, event=False, pct=0.10):
    mu, sigma, df = _predictive_params(model, weekday=weekday, tmin=tmin, tmax=tmax, precip=precip, event=event)
    point = np.expm1(mu)
    lo_log = np.log1p(point * (1 - pct))
    hi_log = np.log1p(point * (1 + pct))
    return float(student_t.cdf((hi_log - mu)/sigma, df) - student_t.cdf((lo_log - mu)/sigma, df))

def prob_at_least(model, *, weekday, tmin, tmax, precip, event=False, threshold=0.0):
    mu, sigma, df = _predictive_params(model, weekday=weekday, tmin=tmin, tmax=tmax, precip=precip, event=event)
    z = (np.log1p(float(threshold)) - mu) / sigma
    return float(1 - student_t.cdf(z, df))

def prob_at_most(model, *, weekday, tmin, tmax, precip, event=False, threshold=0.0):
    mu, sigma, df = _predictive_params(model, weekday=weekday, tmin=tmin, tmax=tmax, precip=precip, event=event)
    z = (np.log1p(float(threshold)) - mu) / sigma
    return float(student_t.cdf(z, df))

# ------------------------------------------------------------
# MODEL TRAINING
# ------------------------------------------------------------
model, meta = load_model(DATA_PATH)
print("Modell trainiert.")
print(f"Formel: {meta['formula']}")
print(f"R^2: {meta['r2']:.3f} | N (Train): {meta['n_model']}")
print(f"Zeitraum: {meta['date_min']} bis {meta['date_max']} | Trim (Top 1%): ~{meta['p99']:.2f} €")
print(f"Score-Kalibrierung (log): q1={meta['score_q1_log']:.3f}, q99={meta['score_q99_log']:.3f}")

# ------------------------------------------------------------
# BEISPIELE
# ------------------------------------------------------------
# Beispiel: Samstag, Tmin=12, Tmax=20, Regen=0, ohne/mit Event
res = predict_revenue(model, weekday="Samstag", tmin=12, tmax=20, precip=0, event=False, alpha=0.10)
score = condition_score(model, meta, weekday="Samstag", tmin=12, tmax=20, precip=0, event=False)
print("\nVorhersage (90%-Intervall) – ohne Event")
print(res); print(f"Bedingungs-Score (0–100): {score:.1f}")

res_ev = predict_revenue(model, weekday="Samstag", tmin=12, tmax=20, precip=0, event=True, alpha=0.10)
score_ev = condition_score(model, meta, weekday="Samstag", tmin=12, tmax=20, precip=0, event=True)
print("\nVorhersage (90%-Intervall) – MIT Event")
print(res_ev); print(f"Bedingungs-Score (0–100): {score_ev:.1f}")

# ------------------------------------------------------------
# Optional interaktiv (Widgets)
# ------------------------------------------------------------
# !pip -q install ipywidgets
import ipywidgets as w
from IPython.display import display

def run(wd, tmin, tmax, precip, event, alpha):
    res = predict_revenue(model, weekday=wd, tmin=tmin, tmax=tmax, precip=precip, event=event, alpha=alpha)
    sc  = condition_score(model, meta, weekday=wd, tmin=tmin, tmax=tmax, precip=precip, event=event)
    print(f"\n{wd=}, {tmin=}, {tmax=}, {precip=}, {event=}")
    print("Punktprognose:", round(res['point']))
    print("90%-Intervall:", round(res['lo90']), "bis", round(res['hi90']))
    print("90%-Floor:", round(res['p90_floor']))
    print(f"Bedingungs-Score (0–100): {sc:.1f}")

display(w.interact(
    run,
    wd=w.Dropdown(options=["Montag","Dienstag","Mittwoch","Donnerstag","Freitag","Samstag","Sonntag"], value="Samstag", description="Wochentag"),
    tmin=w.FloatSlider(min=-10, max=30, step=0.5, value=12, description="Tmin °C"),
    tmax=w.FloatSlider(min=-5, max=40, step=0.5, value=20, description="Tmax °C"),
    precip=w.FloatSlider(min=0, max=60, step=0.5, value=0, description="Regen mm"),
    event=w.Checkbox(value=False, description="Eventtag"),
    alpha=w.FloatSlider(min=0.01, max=0.5, step=0.01, value=0.10, description="alpha")
))
# ==== FRONTEND AB HIER ====
import streamlit as st
from pathlib import Path
import hashlib

st.set_page_config(page_title="Mankei Forecast", page_icon="📈", layout="wide")
st.title("📈 Mankei Umsatz-Prognose (Tmin/Tmax + Regen + Event)")

# --- Sidebar: Datei & Modell ---
st.sidebar.header("Daten & Modell")
uploaded = st.sidebar.file_uploader("Excel (2023–2024) hochladen", type=["xlsx","xls"])
retrain = st.sidebar.button("Modell laden / neu laden")

@st.cache_resource(show_spinner=True)
def _train_from_bytes(file_bytes: bytes, fname: str):
    """Trainiert Modell aus hochgeladener Excel (Cache-Key = Datei-Hash)."""
    import tempfile
    h = hashlib.sha256(file_bytes).hexdigest()[:12]
    tmp = Path(tempfile.gettempdir()) / f"{h}_{fname}"
    with open(tmp, "wb") as f:
        f.write(file_bytes)
    model, meta = load_model(tmp)
    return model, meta, tmp

MODEL = None
META = None
if uploaded and retrain:
    MODEL, META, TMP = _train_from_bytes(uploaded.getvalue(), uploaded.name)
    st.sidebar.success(
        f"Modell geladen | Zeitraum {META.get('date_min','?')}–{META.get('date_max','?')}"
        f" | N={META.get('n_model','?')} | R²={META.get('r2',0):.3f}"
    )
    st.sidebar.caption(
        f"Eingaberanges: Tmin≈[{META.get('tmin_q01',-50):.1f},{META.get('tmin_q99',50):.1f}] °C • "
        f"Tmax≈[{META.get('tmax_q01',-50):.1f},{META.get('tmax_q99',50):.1f}] °C • "
        f"Regen≤{META.get('precip_q99',100):.1f} mm"
    )

# --- Eingaben ---
col = st.columns([1,1,1,1,1,1])
weekday = col[0].selectbox("Wochentag", ["Montag","Dienstag","Mittwoch","Donnerstag","Freitag","Samstag","Sonntag"], index=5)
tmin    = col[1].number_input("Tmin (°C)", -30.0, 50.0, 12.0, 0.5)
tmax    = col[2].number_input("Tmax (°C)", -20.0, 60.0, 20.0, 0.5)
precip  = col[3].number_input("Regen (mm)", 0.0, 300.0, 0.0, 0.5)
event   = col[4].toggle("Eventtag", value=False)
alpha   = col[5].slider("alpha (1 - Konfidenz)", 0.01, 0.50, 0.10, 0.01)

go = st.button("🔮 Prognose berechnen", type="primary", use_container_width=True)

# --- Ausgabe ---
if go:
    if uploaded is None or META is None:
        st.warning("Bitte zuerst Excel hochladen und **Modell laden / neu laden** drücken.")
    else:
        res = predict_revenue(MODEL, weekday=weekday, tmin=tmin, tmax=tmax, precip=precip, event=event, alpha=alpha)
        score = condition_score(MODEL, META, weekday=weekday, tmin=tmin, tmax=tmax, precip=precip, event=event)

        m1, m2, m3, m4 = st.columns(4)
        m1.metric("Punktprognose (€)", f"{round(res['point']):,}".replace(",", "."))
        m2.metric("90%-Floor (€)",     f"{round(res['lo90']):,}".replace(",", "."))
        m3.metric("90%-Obergrenze (€)",f"{round(res['hi90']):,}".replace(",", "."))
        m4.metric("Score (0–100)",     f"{score:.1f}")

        with st.expander("Details (Inputs & Rohwerte)"):
            st.json({
                "Inputs": {
                    "Wochentag": weekday,
                    "Tmin (°C)": float(tmin),
                    "Tmax (°C)": float(tmax),
                    "Regen (mm)": float(precip),
                    "Eventtag": bool(event),
                    "alpha": float(alpha)
                },
                "Model-Inputs": res["inputs"],
                "Ergebnisse": {
                    "Punkt (€)": res["point"],
                    "PI_lo (€)": res["lo90"],
                    "PI_hi (€)": res["hi90"],
                    "Score": score
                }
            })

        # Download der Ergebnisse
        csv = ("feld;wert\n"
               f"Wochentag;{weekday}\n"
               f"Tmin;{tmin}\nTmax;{tmax}\nRegen;{precip}\nEvent;{int(bool(event))}\nalpha;{alpha}\n"
               f"Punkt (€);{round(res['point'])}\nPI 90% Lower (€);{round(res['lo90'])}\nPI 90% Upper (€);{round(res['hi90'])}\n"
               f"Score;{score:.1f}\n").encode("utf-8")
        st.download_button("📥 Ergebnisse als CSV", data=csv, file_name="mankei_forecast.csv", mime="text/csv")

st.markdown("---")
st.caption("Hinweis: Das Modell wird jedes Mal neu auf der hochgeladenen Excel trainiert. "
           "Eingaben werden auf Trainings-Quantilen geclamped (Meta).")
